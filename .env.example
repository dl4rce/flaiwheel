# ══════════════════════════════════════════════════
#  Flaiwheel – Configuration
# ══════════════════════════════════════════════════

# ── Documentation ────────────────────────────────
# Path to your .md files (for volume mount)
DOCS_PATH=./my-project/docs

# ── OR: Git repo (auto-cloned) ──────────────────
# GIT_REPO_URL=https://github.com/your-team/docs.git
# GIT_BRANCH=main
# GIT_SYNC_INTERVAL=300    # seconds (0 = disabled)
# GIT_TOKEN=ghp_xxx        # for private repos
# GIT_AUTO_PUSH=true       # auto-commit + push bugfix summaries
# WEBHOOK_SECRET=          # GitHub webhook secret for /webhook/github endpoint

# ── Embedding Model ─────────────────────────────
# "local" = free, runs locally in container
# "openai" = better quality, requires API key
EMBEDDING_PROVIDER=local

# Local models (selectable in Web UI):
#   all-MiniLM-L6-v2                → Fast, 90MB RAM
#   all-MiniLM-L12-v2               → Balanced
#   all-mpnet-base-v2               → Good, 420MB RAM
#   BAAI/bge-base-en-v1.5           → Very good EN, 420MB
#   nomic-ai/nomic-embed-text-v1.5  → Best quality, 520MB
#   intfloat/multilingual-e5-base   → Multilingual, 1.1GB
#   BAAI/bge-m3                     → Best multilingual, 2.2GB
EMBEDDING_MODEL=all-MiniLM-L6-v2

# OpenAI (only if EMBEDDING_PROVIDER=openai)
# OPENAI_API_KEY=sk-...

# ── Chunking ────────────────────────────────────
# heading = split at ## headings (recommended)
# fixed   = fixed size with overlap
# hybrid  = heading + subdivide large chunks
CHUNK_STRATEGY=heading

# ── Ports ───────────────────────────────────────
WEB_PORT=8080     # Web UI
SSE_PORT=8081     # MCP SSE endpoint
