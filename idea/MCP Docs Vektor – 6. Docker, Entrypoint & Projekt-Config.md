# MCP Docs Vektor â€“ Code Teil 6: Docker, Entrypoint & Projekt-Config

## `Dockerfile`

```dockerfile
FROM python:3.12-slim

# System-Dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends git curl && \
    rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Python Dependencies zuerst (fÃ¼r Docker Layer Caching)
COPY pyproject.toml .
RUN pip install --no-cache-dir .

# Embedding-Modell vorladen (damit erster Start schnell ist)
# Default: all-MiniLM-L6-v2 (22M params, ~90MB)
RUN python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('all-MiniLM-L6-v2')"

# Source Code
COPY src/ src/
COPY scripts/ scripts/
RUN chmod +x scripts/*.sh

# Volumes
# /docs  = Deine Markdown-Dokumentation (mount oder git clone)
# /data  = Vektor-Index + Config (persistent!)
VOLUME ["/docs", "/data"]

# Default Environment
ENV MCP_DOCS_PATH=/docs \
    MCP_VECTORSTORE_PATH=/data/vectorstore \
    MCP_EMBEDDING_PROVIDER=local \
    MCP_EMBEDDING_MODEL=all-MiniLM-L6-v2 \
    MCP_CHUNK_STRATEGY=heading \
    MCP_TRANSPORT=sse \
    MCP_SSE_PORT=8081 \
    MCP_WEB_PORT=8080

# Ports
# 8080 = Web-UI
# 8081 = MCP SSE Transport
EXPOSE 8080 8081

# Health Check
HEALTHCHECK --interval=30s --timeout=5s --retries=3 \
    CMD curl -f http://localhost:8080/api/stats || exit 1

ENTRYPOINT ["scripts/entrypoint.sh"]
```

* * *

## `scripts/entrypoint.sh`

```bash
#!/bin/bash
set -e

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘  ğŸ” MCP Docs Vector Server                  â•‘"
echo "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£"
echo "â•‘  Docs:       ${MCP_DOCS_PATH}               "
echo "â•‘  Embeddings: ${MCP_EMBEDDING_PROVIDER} (${MCP_EMBEDDING_MODEL})"
echo "â•‘  Transport:  ${MCP_TRANSPORT}                "
echo "â•‘  Web-UI:     http://0.0.0.0:${MCP_WEB_PORT} "
echo "â•‘  MCP SSE:    http://0.0.0.0:${MCP_SSE_PORT} "
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

# Verzeichnisse sicherstellen
mkdir -p /data/vectorstore

# Optional: Git Clone wenn URL gesetzt und /docs leer
if [ -n "${MCP_GIT_REPO_URL}" ] && [ ! "$(ls -A ${MCP_DOCS_PATH} 2>/dev/null)" ]; then
    echo ""
    echo "ğŸ“¥ Cloning ${MCP_GIT_REPO_URL} (branch: ${MCP_GIT_BRANCH:-main})..."
    
    CLONE_URL="${MCP_GIT_REPO_URL}"
    if [ -n "${MCP_GIT_TOKEN}" ]; then
        CLONE_URL=$(echo "${CLONE_URL}" | sed "s|https://|https://${MCP_GIT_TOKEN}@|")
    fi
    
    git clone \
        --branch "${MCP_GIT_BRANCH:-main}" \
        --single-branch \
        --depth 1 \
        "${CLONE_URL}" "${MCP_DOCS_PATH}"
    
    echo "âœ… Clone abgeschlossen"
fi

# Starte Web-UI + MCP Server parallel
echo ""
echo "ğŸš€ Starting services..."

# Web-UI im Hintergrund
python -m mcp_docs_vector.web &
WEB_PID=$!

# MCP Server im Vordergrund
python -m mcp_docs_vector.server &
MCP_PID=$!

echo "âœ… Web-UI PID: ${WEB_PID}, MCP PID: ${MCP_PID}"

# Warte auf beide Prozesse
wait -n
exit $?
```

* * *

## `scripts/reindex.sh`

```bash
#!/bin/bash
# Manueller Reindex-Trigger via CLI
echo "ğŸ”„ Triggering reindex..."
curl -s -X POST http://localhost:8080/api/reindex | python -m json.tool
```

* * *

## `pyproject.toml`

```toml
[project]
name = "mcp-docs-vector"
version = "0.1.0"
description = "Self-contained MCP server with vector-indexed documentation search"
readme = "README.md"
license = {text = "MIT"}
requires-python = ">=3.11"

dependencies = [
    # MCP Server
    "mcp[cli]>=1.0.0",
    
    # Vektor-DB
    "chromadb>=0.5.0",
    
    # Lokale Embeddings
    "sentence-transformers>=3.0.0",
    
    # Web-UI
    "fastapi>=0.115.0",
    "uvicorn[standard]>=0.30.0",
    
    # Config
    "pydantic-settings>=2.0.0",
]

[project.optional-dependencies]
# FÃ¼r OpenAI Embeddings (optional)
openai = ["openai>=1.0.0"]

# FÃ¼r Entwicklung
dev = [
    "pytest>=8.0",
    "httpx>=0.27",  # FÃ¼r FastAPI Tests
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/mcp_docs_vector"]
```

* * *

## `docker-compose.yml`

```yaml
version: "3.8"

services:
  mcp-docs:
    build: .
    # Oder vom Registry:
    # image: ghcr.io/dein-user/mcp-docs-vector:latest
    
    ports:
      - "${WEB_PORT:-8080}:8080"     # Web-UI
      - "${SSE_PORT:-8081}:8081"     # MCP SSE Transport
    
    volumes:
      # === OPTION A: Lokale Docs mounten ===
      - ${DOCS_PATH:-./example-docs}:/docs:ro
      
      # === Persistenter Index (Ã¼berlebt Container-Restarts) ===
      - mcp-data:/data
    
    environment:
      # Embedding
      - MCP_EMBEDDING_PROVIDER=${EMBEDDING_PROVIDER:-local}
      - MCP_EMBEDDING_MODEL=${EMBEDDING_MODEL:-all-MiniLM-L6-v2}
      
      # OpenAI (optional)
      - MCP_OPENAI_API_KEY=${OPENAI_API_KEY:-}
      
      # Git (optional, alternativ zu Volume-Mount)
      - MCP_GIT_REPO_URL=${GIT_REPO_URL:-}
      - MCP_GIT_BRANCH=${GIT_BRANCH:-main}
      - MCP_GIT_SYNC_INTERVAL=${GIT_SYNC_INTERVAL:-300}
      - MCP_GIT_TOKEN=${GIT_TOKEN:-}
      
      # Chunking
      - MCP_CHUNK_STRATEGY=${CHUNK_STRATEGY:-heading}
      
      # Transport
      - MCP_TRANSPORT=sse
    
    restart: unless-stopped
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/stats"]
      interval: 30s
      timeout: 5s
      retries: 3

volumes:
  mcp-data:
    name: mcp-docs-vectorstore
```

* * *

## `.env.example`

```env
# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  MCP Docs Vector â€“ Konfiguration                    â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â”€â”€ Dokumentation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Pfad zu deinen .md Dateien (fÃ¼r Volume-Mount)
DOCS_PATH=./my-project/docs

# â”€â”€ ODER: Git Repo (wird automatisch geklont) â”€â”€â”€â”€â”€â”€â”€â”€
# GIT_REPO_URL=https://github.com/your-team/docs.git
# GIT_BRANCH=main
# GIT_SYNC_INTERVAL=300    # Sekunden (0 = aus)
# GIT_TOKEN=ghp_xxx        # FÃ¼r private Repos

# â”€â”€ Embedding Modell â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# "local" = kostenlos, lÃ¤uft lokal im Container
# "openai" = besser, braucht API-Key
EMBEDDING_PROVIDER=local

# Lokale Modelle (wÃ¤hlbar in Web-UI):
#   all-MiniLM-L6-v2              â†’ âš¡ Schnell, 90MB RAM
#   all-MiniLM-L12-v2             â†’ Ausgewogen
#   all-mpnet-base-v2             â†’ Gut, 420MB RAM
#   BAAI/bge-base-en-v1.5         â†’ Sehr gut EN, 420MB
#   nomic-ai/nomic-embed-text-v1.5 â†’ ğŸ† Beste QualitÃ¤t, 520MB
#   intfloat/multilingual-e5-base  â†’ ğŸŒ Mehrsprachig, 1.1GB
#   BAAI/bge-m3                    â†’ ğŸŒ Bestes Multilingual, 2.2GB
EMBEDDING_MODEL=all-MiniLM-L6-v2

# OpenAI (nur wenn EMBEDDING_PROVIDER=openai)
# OPENAI_API_KEY=sk-...

# â”€â”€ Chunking â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# heading = Split an ## Headings (empfohlen)
# fixed   = Feste GrÃ¶ÃŸe mit Overlap
# hybrid  = Heading + Unterteilen bei zu groÃŸen Chunks
CHUNK_STRATEGY=heading

# â”€â”€ Ports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
WEB_PORT=8080     # Web-UI
SSE_PORT=8081     # MCP SSE Endpoint
```

* * *

## `src/mcp_docs_vector/__init__.py`

```python
"""MCP Docs Vector â€“ Self-contained vector-indexed documentation search."""
__version__ = "0.1.0"
```

* * *

## `src/mcp_docs_vector/__main__.py`

```python
"""ErmÃ¶glicht `python -m mcp_docs_vector`"""
import sys
import threading
from .config import Config
from .web import run_web
from .server import run_mcp

def main():
    config = Config.load()
    
    # Web-UI in eigenem Thread
    web_thread = threading.Thread(target=run_web, daemon=True)
    web_thread.start()
    
    # MCP Server im Main Thread
    run_mcp()

if __name__ == "__main__":
    main()
```

* * *

## `examples/cursor-mcp.json`

```json
{
  "mcpServers": {
    "project-docs": {
      "url": "http://localhost:8081/sse"
    }
  }
}
```

## `examples/claude-desktop.json`

```json
{
  "mcpServers": {
    "project-docs": {
      "url": "http://localhost:8081/sse"
    }
  }
}
```

* * *

## Quickstart

```bash
# 1. Repo klonen
git clone https://github.com/dein-user/mcp-docs-vector.git
cd mcp-docs-vector

# 2. Config anpassen
cp .env.example .env
# â†’ DOCS_PATH oder GIT_REPO_URL eintragen

# 3. Starten
docker-compose up -d

# 4. Web-UI Ã¶ffnen
open http://localhost:8080

# 5. In Cursor: .cursor/mcp.json
# { "mcpServers": { "project-docs": { "url": "http://localhost:8081/sse" } } }

# 6. Fertig! ğŸ‰
```